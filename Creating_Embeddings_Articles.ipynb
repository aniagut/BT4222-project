{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!pip install transformers torch\n",
    " "
   ]
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-10-27T15:14:03.922801Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from ArticleDataset import ArticlesDataset\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from transformers import AdamW\n",
    "import numpy as np\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "import os\n",
    "os.environ['HF_HUB_DISABLE_SYMLINKS_WARNING'] = '1'\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Maltehb/danish-bert-botxo\")\n",
    "model = AutoModel.from_pretrained(\"Maltehb/danish-bert-botxo\")\n",
    "\n",
    "\n",
    "dataset_type = \"ebnerd_demo\"\n",
    "base_path = os.path.join(\".\", dataset_type)\n",
    "text_column = 'body'\n",
    "articles_columns = [\"article_id\", \"premium\", \"category\", \"sentiment_score\", \"body\"]\n",
    "#load data articles\n",
    "articles_path = os.path.join(base_path, \"articles.parquet\")\n",
    "\n",
    "parquet_file = pq.ParquetFile(articles_path)\n",
    "print(parquet_file.schema.names)\n",
    "\n",
    "articles = pd.read_parquet(articles_path)[articles_columns]\n",
    "\n",
    "\n",
    "num_epochs = 10\n",
    "articles_dataset = ArticlesDataset(articles, tokenizer)\n",
    "articles_loader = DataLoader(articles_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "\n",
    "# Load model in evaluation mode\n",
    "model.eval()\n",
    "article_ids = []\n",
    "all_embeddings = []\n",
    "\n",
    "# Extract embeddings\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(articles_loader):\n",
    "        outputs = model(input_ids=batch['input_ids'], attention_mask=batch['attention_mask'])\n",
    "        embeddings = outputs.last_hidden_state[:, 0, :].cpu().numpy()  # Get the token embeddings\n",
    "        all_embeddings.append(embeddings)\n",
    "        article_ids.extend(batch['article_id'].numpy())\n",
    "\n",
    "# Concatenate all embeddings into one array\n",
    "all_embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "\n",
    "# Create a df to store article IDs with their embeddings\n",
    "embeddings_df = pd.DataFrame(all_embeddings)\n",
    "embeddings_df['article_id'] = article_ids\n",
    "\n",
    "# Save embeddings to a file for later use\n",
    "embeddings_df.to_parquet('./article_embeddings.parquet')\n",
    "\n",
    "print(\"Embeddings saved successfully.\")\n",
    "\n",
    "\n",
    "#touseembeddingslater\n",
    "embeddings_df = pd.read_parquet('./article_embeddings.parquet')\n",
    "# Use embeddings_df as needed"
   ],
   "id": "f5181c5ed930dd1c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['article_id', 'title', 'subtitle', 'last_modified_time', 'premium', 'body', 'published_time', 'item', 'article_type', 'url', 'item', 'item', 'item', 'category', 'item', 'category_str', 'total_inviews', 'total_pageviews', 'total_read_time', 'sentiment_score', 'sentiment_label']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|â–Ž         | 23/737 [05:59<3:21:03, 16.90s/it]"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "f2e11581141ddb4c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
