{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/BT4222/')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3HS5tUZxlHct",
    "outputId": "56d0c3a3-9779-4711-8c46-298d4f21e4eb"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k0SytZTFk6sP",
    "outputId": "3432a35d-16b8-4d39-8412-7d6ae52dbe7e"
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import pyarrow.parquet as pq\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from gensim.models.fasttext import load_facebook_vectors  # For using embeddings only\n",
    "\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('averaged_perceptron_tagger')  # for POS tagging, necessary for better lemmatization\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('danish'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "model = load_facebook_vectors('cc.da.300.bin')\n",
    "dataset_type = \"ebnerd_demo\"\n",
    "base_path = os.path.join(\".\", dataset_type)\n",
    "\n",
    "text_column = 'title'\n",
    "articles_columns = [\"article_id\", \"title\"]\n",
    "all_articles = pd.read_parquet('articles.parquet')[articles_columns]\n",
    "\n",
    "\n",
    "cols_hist = ['user_id', 'article_id_fixed']\n",
    "\n",
    "history_articles_train = pd.read_parquet('train/history.parquet')[cols_hist]\n",
    "history_articles_val = pd.read_parquet('validation/history.parquet')[cols_hist]\n",
    "history_articles_train.rename(columns={'article_id_fixed' : 'article_id'}, inplace=True)\n",
    "history_articles_val.rename(columns={'article_id_fixed': 'article_id'}, inplace=True)\n",
    "history_articles = pd.concat([history_articles_train, history_articles_val], ignore_index=True)\n",
    "\n",
    "\n",
    "def preprocess_behaviors(behaviors_ds):\n",
    "    selected_columns = ['impression_id', 'article_id', 'user_id', 'is_sso_user', 'is_subscriber', 'age', 'gender', 'device_type']\n",
    "    filtered_data = behaviors_ds[selected_columns]\n",
    "\n",
    "    # Convert columns to numerical values\n",
    "    filtered_data['article_id'] = pd.to_numeric(filtered_data['article_id'].fillna(0), downcast='integer')\n",
    "    filtered_data['age'] = pd.to_numeric(filtered_data['age'].fillna(0), downcast='integer')\n",
    "    filtered_data['gender'] = pd.to_numeric(filtered_data['gender'].fillna(-1), downcast='integer')\n",
    "\n",
    "    # One-hot encoding for device_type and gender\n",
    "    device_one_hot = pd.get_dummies(filtered_data['device_type'], prefix='device_type')\n",
    "    filtered_data = pd.concat([filtered_data, device_one_hot], axis=1).drop(columns=['device_type'])\n",
    "\n",
    "    gender_one_hot = pd.get_dummies(filtered_data['gender'], prefix='gender')\n",
    "    filtered_data = pd.concat([filtered_data, gender_one_hot], axis=1).drop(columns=['gender'])\n",
    "\n",
    "    # Convert boolean columns to integers\n",
    "    filtered_data['is_sso_user'] = filtered_data['is_sso_user'].astype(int)\n",
    "    filtered_data['is_subscriber'] = filtered_data['is_subscriber'].astype(int)\n",
    "\n",
    "    return filtered_data\n",
    "\n",
    "\n",
    "# Define an Embedding Model in PyTorch\n",
    "class ImpressionEmbeddingModel(nn.Module):\n",
    "    def __init__(self, input_dim, embedding_dim):\n",
    "        super(ImpressionEmbeddingModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.embedding(x)\n",
    "\n",
    "# Custom Dataset for impression IDs\n",
    "class ImpressionDataset(Dataset):\n",
    "    def __init__(self, impression_ids):\n",
    "        self.impression_ids = impression_ids\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.impression_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.impression_ids[idx], dtype=torch.long)\n",
    "\n",
    "# Function to create embeddings\n",
    "def create_impression_embeddings_df(filtered_data, embedding_dim=8, batch_size=512):\n",
    "    # Step 1: Create a mapping for impression_id to continuous indices\n",
    "    unique_impressions = filtered_data[['impression_id', 'user_id']].drop_duplicates()\n",
    "    unique_impressions.reset_index(drop=True, inplace=True)\n",
    "    impression_mapping = {orig_id: new_id for new_id, orig_id in enumerate(unique_impressions['impression_id'])}\n",
    "\n",
    "    # Map impression IDs in filtered_data\n",
    "    filtered_data['mapped_impression_id'] = filtered_data['impression_id'].map(impression_mapping)\n",
    "\n",
    "    # Define model\n",
    "    input_dim = len(impression_mapping)  # Number of unique impressions\n",
    "    model = ImpressionEmbeddingModel(input_dim=input_dim, embedding_dim=embedding_dim)\n",
    "    model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "\n",
    "    # Create Dataset and DataLoader for batch processing\n",
    "    impression_dataset = ImpressionDataset(impression_ids=list(impression_mapping.values()))\n",
    "    impression_loader = DataLoader(impression_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Collect embeddings\n",
    "    embeddings_list = []\n",
    "    with torch.no_grad():\n",
    "        for batch in impression_loader:\n",
    "            batch = batch.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "            embeddings = model(batch)\n",
    "            embeddings_list.extend(embeddings.cpu().numpy())  # Move to CPU for storing in a list\n",
    "\n",
    "   #create a DataFrame with the original impression IDs and embeddings\n",
    "    embeddings_df = pd.DataFrame({\n",
    "        'impression_id': unique_impressions['impression_id'],\n",
    "        'user_id': unique_impressions['user_id'],\n",
    "        'user_embeddings': [embedding.tolist() for embedding in embeddings_list]\n",
    "    })\n",
    "\n",
    "    return embeddings_df\n",
    "\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "\n",
    "def clean_and_tokenize(title):\n",
    "    # Remove punctuation from title\n",
    "    title_cleaned = title.translate(str.maketrans('', '', string.punctuation))\n",
    "    words = word_tokenize(title_cleaned.lower())\n",
    "    words_lemmatized = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in words]\n",
    "    return [w for w in words_lemmatized if not w in stop_words]\n",
    "\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "def build_vocabs(titles):\n",
    "  all_words = [word for title in titles for word in title]\n",
    "  word_count = Counter(all_words)\n",
    "  vocabulary = {word: idx + 1 for idx, (word, count) in enumerate(word_count.items())}\n",
    "  vocabulary['<UNK>'] = 0\n",
    "  return vocabulary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_embedding_sequence(title, model):\n",
    "    embedding_sequence = []\n",
    "    for word in title:  # Assuming 'title' is a list of words\n",
    "        if word in model:  # Check if the word is in the model\n",
    "            embedding_sequence.append(model[word])\n",
    "        else:\n",
    "            embedding_sequence.append(np.zeros(model.vector_size))  # Zero vector for unknown words\n",
    "\n",
    "    if len(embedding_sequence) == 0:\n",
    "        print(\"Entirely empty sequence, creating a fully empty sequence\")\n",
    "        # Entirely empty sequence, create a single zero vector (or empty array if desired)\n",
    "        embedding_sequence = np.zeros((1, model.vector_size))\n",
    "    else:\n",
    "        embedding_sequence = np.array(embedding_sequence)\n",
    "\n",
    "    print(\"Embedding sequence shape:\", embedding_sequence.shape)\n",
    "    return embedding_sequence\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vocabulary = build_vocabs(all_articles[text_column])  #vocabulary 15432\n",
    "all_articles[text_column] = all_articles[text_column].apply(clean_and_tokenize)\n",
    "# Apply the function to each row in the DataFrame to create sequences\n",
    "all_articles['title_embedding_sequence'] = all_articles['title'].apply(lambda x: get_embedding_sequence(x, model))\n",
    "articles_embeddings_dict = dict(zip(all_articles['article_id'], all_articles['title_embedding_sequence']))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "filePath_with_all_features = r\"/content/drive/MyDrive/BT4222/xgboost_dataset_ebnerd_demo.parquet\"\n",
    "data = pd.read_parquet(filePath_with_all_features)\n",
    "print(data.columns.values)\n",
    "\n",
    "\n",
    "# Load the original behavior data\n",
    "original_behaviors_train = pd.read_parquet(r\"/content/drive/MyDrive/BT4222/train/behaviors.parquet\")\n",
    "original_behaviors_valid = pd.read_parquet(r\"/content/drive/MyDrive/BT4222/validation/behaviors.parquet\")\n",
    "\n",
    "# Preprocess behaviors data\n",
    "preprocessed_behaviors_train = preprocess_behaviors(original_behaviors_train)\n",
    "preprocessed_behaviors_valid = preprocess_behaviors(original_behaviors_valid)\n",
    "\n",
    "# Define the embedding dimension\n",
    "embedding_dim = 8\n",
    "\n",
    "# Generate impression embeddings for the training and validation datasets\n",
    "embeddings_df_train = create_impression_embeddings_df(preprocessed_behaviors_train, embedding_dim)\n",
    "embeddings_df_valid = create_impression_embeddings_df(preprocessed_behaviors_valid, embedding_dim)\n",
    "\n",
    "# Concatenate training and validation embeddings into one DataFrame\n",
    "embeddings_user = pd.concat([embeddings_df_train, embeddings_df_valid], axis=0).reset_index(drop=True)\n",
    "\n",
    "# Now `embeddings_user` contains both training and validation impression embeddings\n",
    "print(embeddings_user.head())\n",
    "\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "embeddings_user.reset_index(drop=True, inplace=True)\n",
    "\n",
    "impression_user_data_cols = ['impression_id', 'user_embeddings', 'user_id']\n",
    "candidate_news_data_cols = ['impression_id', 'article_id', 'clicked','user_id']\n",
    "candidate_news_data = data[candidate_news_data_cols]\n",
    "data = pd.merge(candidate_news_data, embeddings_user, on=['impression_id','user_id'])\n",
    "data['clicked'] = data['clicked'].astype(int)\n",
    "\n",
    "impression_ids = data['impression_id'].unique()\n",
    "\n",
    "# Convert columns to numeric, coercing errors to NaN\n",
    "data['impression_id'] = pd.to_numeric(data['impression_id'], errors='coerce')\n",
    "data['article_id'] = pd.to_numeric(data['article_id'], errors='coerce')\n",
    "data['clicked'] = pd.to_numeric(data['clicked'], errors='coerce')\n",
    "data['user_id'] = pd.to_numeric(data['user_id'], errors='coerce')\n",
    "\n",
    "# Drop rows with NaN values (which were non-numeric initially)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "# Convert to integers if needed\n",
    "data['impression_id'] = data['impression_id'].astype(int)\n",
    "data['article_id'] =data['article_id'].astype(int)\n",
    "data['clicked'] = data['clicked'].astype(int)\n",
    "data['user_id'] = data['user_id'].astype(int)\n",
    "\n",
    "# Verify data types and output a sample\n",
    "print(data.dtypes)\n",
    "print(data.head())\n",
    "\n",
    "# Split impression IDs into training and temporary sets (temporary will be split into validation and test)\n",
    "train_ids, temp_ids = train_test_split(impression_ids, test_size=0.4, random_state=42)  # 60% train, 40% temp\n",
    "val_ids, test_ids = train_test_split(temp_ids, test_size=0.5, random_state=42)  # Split temp into 20% val, 20% test\n",
    "# Split the actual data based on IDs\n",
    "data.reset_index(inplace=True)\n",
    "train_data = data[data['impression_id'].isin(train_ids)]\n",
    "val_data = data[data['impression_id'].isin(val_ids)]\n",
    "test_data = data[data['impression_id'].isin(test_ids)]\n",
    "history_articles.rename(columns={'article_id' : 'clicked_article_ids'},inplace=True)\n",
    "impression_user_data_train, candidate_news_data_train = train_data[impression_user_data_cols], train_data[candidate_news_data_cols]\n",
    "impression_user_data_val, candidate_news_data_val = val_data[impression_user_data_cols], val_data[candidate_news_data_cols]\n",
    "impression_user_data_test, candidate_news_data_test = test_data[impression_user_data_cols], test_data[candidate_news_data_cols]\n",
    "\n",
    "\n",
    "\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "DATASET"
   ],
   "metadata": {
    "id": "OIft5jZslw5-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class NPA_Dataset(Dataset):\n",
    "    def __init__(self, historical_clicks, impression_user_data, candidate_news_data, article_embedding_dict, embedding_dim=300):\n",
    "        super(NPA_Dataset, self).__init__()\n",
    "        self.impression_user_data = impression_user_data.set_index('impression_id', drop=False)\n",
    "        self.candidate_news_data = candidate_news_data.set_index('impression_id', drop=False)\n",
    "        self.historical_clicks = historical_clicks\n",
    "        self.article_embedding_dict = article_embedding_dict\n",
    "        self.default_embedding = np.zeros(embedding_dim)\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.impression_user_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieve information for the current impression\n",
    "        impression_info = self.impression_user_data.iloc[idx]\n",
    "        impression_id = impression_info.name\n",
    "        user_id = impression_info['user_id']\n",
    "\n",
    "        # User features\n",
    "        user_features = torch.tensor(impression_info['user_embeddings'], dtype=torch.float32)\n",
    "\n",
    "        # Candidate news embeddings\n",
    "        candidate_articles = self.candidate_news_data.loc[impression_id]\n",
    "        candidate_news_embeddings = [\n",
    "            torch.tensor(self.article_embedding_dict.get(article_id, self.default_embedding), dtype=torch.float32)\n",
    "            for article_id in candidate_articles['article_id'].tolist()\n",
    "        ]\n",
    "\n",
    "        # Historical news embeddings\n",
    "        historical_article_ids = self.historical_clicks.loc[self.historical_clicks['user_id'] == user_id, 'clicked_article_ids'].iloc[0]\n",
    "        historical_news_embeddings = [\n",
    "            torch.tensor(self.article_embedding_dict.get(article_id, self.default_embedding), dtype=torch.float32)\n",
    "            for article_id in historical_article_ids\n",
    "        ]\n",
    "\n",
    "        # Labels\n",
    "        labels = torch.tensor(candidate_articles['clicked'].values, dtype=torch.float32)\n",
    "\n",
    "        return (candidate_news_embeddings, historical_news_embeddings, user_features), labels\n"
   ],
   "metadata": {
    "id": "4d8zWkpkl0s-"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class UserPreferenceQuery(nn.Module):\n",
    "    def __init__(self, num_filters, query_dim_d, embedding_dim):\n",
    "        super(UserPreferenceQuery, self).__init__()\n",
    "        # Ensure query_dim_w matches num_filters from NewsEncoder\n",
    "        self.Vw = nn.Linear(embedding_dim, num_filters, bias=False)  # Match num_filters\n",
    "        self.vw = nn.Parameter(torch.zeros(num_filters))  # Learnable parameter for word-level query\n",
    "\n",
    "        # Document-level query dimension should match query_dim_d expected in UserEncoder\n",
    "        self.Vd = nn.Linear(embedding_dim, query_dim_d, bias=False)\n",
    "        self.vd = nn.Parameter(torch.zeros(query_dim_d))  # Learnable parameter for document-level query\n",
    "\n",
    "    def forward(self, user_embedding):\n",
    "        # Project user embedding to obtain word and document queries\n",
    "        qd = F.relu(self.Vd(user_embedding) + self.vd)  # Document-level query\n",
    "        qw = F.relu(self.Vw(user_embedding) + self.vw)  # Word-level query\n",
    "        return qw, qd\n",
    "\n",
    "\n",
    "\n",
    "class NewsEncoder(nn.Module):\n",
    "    def __init__(self, num_filters, filter_size, embedding_dim, query_dim):\n",
    "        super(NewsEncoder, self).__init__()\n",
    "        self.conv = nn.Conv1d(in_channels=embedding_dim, out_channels=num_filters, kernel_size=filter_size, padding='same')\n",
    "        self.query_projection = nn.Linear(query_dim, num_filters)  # Project `qw` to match `num_filters`\n",
    "        self.score_projection = nn.Linear(num_filters, 1, bias=False)  # Projection layer for attention scoring\n",
    "        self.num_filters =num_filters\n",
    "\n",
    "    def forward(self, inputs, query_vector, mask=None):\n",
    "        batch_size, num_articles, seq_len, embedding_dim = inputs.shape\n",
    "\n",
    "        # Reshape inputs for Conv1d: [batch_size * num_articles, embedding_dim, seq_len]\n",
    "        inputs = inputs.view(batch_size * num_articles, embedding_dim, seq_len)\n",
    "\n",
    "        # Apply Conv1d and activation\n",
    "        x = F.relu(self.conv(inputs))  # Shape: [batch_size * num_articles, num_filters, seq_len]\n",
    "        x = x.transpose(1, 2)  # Shape: [batch_size * num_articles, seq_len, num_filters]\n",
    "\n",
    "        # Adjust `query_vector` shape to match number of articles\n",
    "        query_vector_projected = self.query_projection(query_vector)\n",
    "        query_vector_projected = query_vector_projected.view(batch_size, 1, self.num_filters).expand(batch_size, num_articles, self.num_filters)\n",
    "        query_vector_projected = query_vector_projected.reshape(batch_size * num_articles, 1, self.num_filters)\n",
    "\n",
    "        # Calculate attention scores\n",
    "        attention_input = torch.tanh(x + query_vector_projected)  # Shape: [batch_size * num_articles, seq_len, num_filters]\n",
    "        attention_scores = torch.softmax(self.score_projection(attention_input), dim=1)\n",
    "\n",
    "        # Apply mask if provided\n",
    "        if mask is not None:\n",
    "            try:\n",
    "                # Reshape `mask` to [batch_size * num_articles, seq_len, 1]\n",
    "                mask = mask.view(batch_size * num_articles, seq_len, 1)\n",
    "                attention_scores = attention_scores * mask\n",
    "                attention_scores = attention_scores / (attention_scores.sum(dim=1, keepdim=True) + 1e-9)\n",
    "            except RuntimeError as e:\n",
    "                print(f\"Mask shape mismatch: {mask.shape}. Expected [{batch_size * num_articles}, {seq_len}, 1].\")\n",
    "                raise e\n",
    "\n",
    "        # Compute context vector as a weighted sum\n",
    "        context_vector = torch.sum(x * attention_scores, dim=1)  # Shape: [batch_size * num_articles, num_filters]\n",
    "        context_vector = context_vector.view(batch_size, num_articles, -1)\n",
    "\n",
    "        return context_vector\n",
    "\n",
    "\n",
    "class UserEncoder(nn.Module):\n",
    "    def __init__(self, query_dim_d, num_filters):\n",
    "        super(UserEncoder, self).__init__()\n",
    "        self.query_projection = nn.Linear(query_dim_d, num_filters, bias=False)  # Project `qd` to match `num_filters`\n",
    "\n",
    "    def forward(self, news_encoder_outputs, query_vector, mask=None):\n",
    "        batch_size, num_clicked_news, num_filters = news_encoder_outputs.shape\n",
    "\n",
    "        # Project `query_vector` (`qd`) to match `num_filters`\n",
    "        query_vector_projected = self.query_projection(query_vector)  # Shape: [batch_size, num_filters]\n",
    "\n",
    "        # Expand `query_vector_projected` across `num_clicked_news` to match `news_encoder_outputs`\n",
    "        query_vector_expanded = query_vector_projected.unsqueeze(1).expand(batch_size, num_clicked_news, num_filters)  # Shape: [batch_size, num_clicked_news, num_filters]\n",
    "\n",
    "        # Calculate attention scores\n",
    "        scores = torch.tanh(news_encoder_outputs + query_vector_expanded).sum(dim=-1)  # Shape: [batch_size, num_clicked_news]\n",
    "        attention_scores = torch.softmax(scores, dim=1)  # Softmax over clicked news items\n",
    "\n",
    "        # Apply mask at the article level\n",
    "        if mask is not None:\n",
    "            # Ensure mask has correct shape: [batch_size, num_clicked_news]\n",
    "            mask = mask.any(dim=-1)  # Aggregate mask across the word sequence to get article-level mask\n",
    "            attention_scores = attention_scores * mask\n",
    "            attention_scores = attention_scores / (attention_scores.sum(dim=1, keepdim=True) + 1e-9)  # Re-normalize\n",
    "\n",
    "        # Weighted sum to get user profile vector\n",
    "        user_profile_vector = torch.sum(attention_scores.unsqueeze(-1) * news_encoder_outputs, dim=1)  # Shape: [batch_size, num_filters]\n",
    "\n",
    "        return user_profile_vector\n",
    "\n",
    "\n",
    "\n",
    "class ClickPredictor(nn.Module):\n",
    "    def forward(self, candidate_news_vectors, user_vector, mask=None):\n",
    "        # Ensure `user_vector` is 2D to match `candidate_news_vectors`\n",
    "        user_vector = user_vector.squeeze(1)  # Shape: [batch_size, num_filters]\n",
    "\n",
    "        # Expand `user_vector` to match `candidate_news_vectors` dimensions\n",
    "        user_vector_expanded = user_vector.unsqueeze(1).expand_as(candidate_news_vectors)  # Shape: [batch_size, num_candidates, num_filters]\n",
    "\n",
    "        # Compute logits (inner product across the last dimension)\n",
    "        logits = torch.sum(candidate_news_vectors * user_vector_expanded, dim=-1)  # Shape: [batch_size, num_candidates]\n",
    "\n",
    "        # Apply mask if provided and in correct shape\n",
    "        if mask is not None:\n",
    "            mask = mask.any(dim=-1)  # Ensure `mask` is reduced to [batch_size, num_candidates]\n",
    "            if mask.shape != logits.shape:\n",
    "                raise RuntimeError(f\"Mask shape {mask.shape} does not match logits shape {logits.shape}\")\n",
    "            logits = logits.masked_fill(~mask, float('-inf'))  # Apply mask\n",
    "\n",
    "        # Apply sigmoid to get probabilities\n",
    "        probabilities = torch.sigmoid(logits)  # Shape: [batch_size, num_candidates]\n",
    "\n",
    "        return probabilities\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class NPA_Model(nn.Module):\n",
    "    def __init__(self, num_filters, filter_size, query_dim_w=8, query_dim_d=8, embeddings_user_dim=8, embeddings_news_dim=300):\n",
    "        super(NPA_Model, self).__init__()\n",
    "        self.user_preference_query = UserPreferenceQuery(query_dim_w, query_dim_d, embeddings_user_dim)\n",
    "        self.news_encoder = NewsEncoder(num_filters=num_filters, filter_size=filter_size, embedding_dim=embeddings_news_dim, query_dim=8)\n",
    "        self.user_encoder = UserEncoder(query_dim_d, num_filters)\n",
    "        self.click_predictor = ClickPredictor()\n",
    "\n",
    "    def forward(self, candidate_news, clicked_news, user_embeddings, candidate_mask=None, clicked_mask=None):\n",
    "        qw, qd = self.user_preference_query(user_embeddings)\n",
    "\n",
    "        candidate_news_vectors = self.news_encoder(candidate_news, qw, mask=candidate_mask)\n",
    "        clicked_news_vectors = self.news_encoder(clicked_news, qw, mask=clicked_mask)\n",
    "\n",
    "        user_profile_vector = self.user_encoder(clicked_news_vectors, qd, mask=clicked_mask)\n",
    "        probabilities = self.click_predictor(candidate_news_vectors, user_profile_vector, mask=candidate_mask)\n",
    "        return probabilities\n"
   ],
   "metadata": {
    "id": "hPkQilC3l153"
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    candidate_news_embeddings, historical_news_embeddings, user_features, candidate_mask, clicked_mask, labels = [], [], [], [], [], []\n",
    "\n",
    "    # Determine maximum sequence length for candidates and clicked news in the batch\n",
    "    max_seq_len_candidates = max(len(news) for (candidates, _, _), _ in batch for news in candidates)\n",
    "    max_seq_len_clicked = max(len(news) for (_, clicked, _), _ in batch for news in clicked)\n",
    "\n",
    "    for (candidates, clicked, user), label in batch:\n",
    "        # Pad each candidate and historical news sequence to ensure consistent `seq_len`\n",
    "        candidates_padded = [F.pad(news, (0, 0, 0, max_seq_len_candidates - news.size(0))) for news in candidates]\n",
    "        clicked_padded = [F.pad(news, (0, 0, 0, max_seq_len_clicked - news.size(0))) for news in clicked]\n",
    "\n",
    "        candidate_news_embeddings.append(torch.stack(candidates_padded))  # Shape: [num_candidates, max_seq_len, embedding_dim]\n",
    "        historical_news_embeddings.append(torch.stack(clicked_padded))    # Shape: [num_clicked, max_seq_len, embedding_dim]\n",
    "\n",
    "        user_features.append(user)\n",
    "\n",
    "        # Create a mask where each article's `seq_len` is represented\n",
    "        candidate_mask.append(torch.ones(len(candidates), max_seq_len_candidates, dtype=torch.bool))  # Shape: [num_candidates, max_seq_len]\n",
    "        clicked_mask.append(torch.ones(len(clicked), max_seq_len_clicked, dtype=torch.bool))          # Shape: [num_clicked, max_seq_len]\n",
    "\n",
    "        labels.append(label)\n",
    "\n",
    "    # Pad embeddings along the 0th dimension\n",
    "    candidate_news_embeddings = pad_sequence(candidate_news_embeddings, batch_first=True)  # Shape: [batch_size, max_num_candidates, max_seq_len, embedding_dim]\n",
    "    historical_news_embeddings = pad_sequence(historical_news_embeddings, batch_first=True)  # Shape: [batch_size, max_num_clicked, max_seq_len, embedding_dim]\n",
    "\n",
    "    # Pad candidate and clicked masks along the 0th dimension to maintain consistent number of articles and word sequence length\n",
    "    candidate_mask = pad_sequence(candidate_mask, batch_first=True, padding_value=0)  # Shape: [batch_size, max_num_candidates, max_seq_len]\n",
    "    clicked_mask = pad_sequence(clicked_mask, batch_first=True, padding_value=0)      # Shape: [batch_size, max_num_clicked, max_seq_len]\n",
    "\n",
    "    user_features = torch.stack(user_features)\n",
    "    labels = pad_sequence(labels, batch_first=True)\n",
    "\n",
    "    return (candidate_news_embeddings, historical_news_embeddings, user_features, candidate_mask, clicked_mask), labels\n"
   ],
   "metadata": {
    "id": "dlJv9K-jPZa3"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Initialize datasets\n",
    "train_dataset = NPA_Dataset(history_articles, impression_user_data_train, candidate_news_data_train, articles_embeddings_dict)\n",
    "val_dataset = NPA_Dataset(history_articles, impression_user_data_val, candidate_news_data_val, articles_embeddings_dict)\n",
    "test_dataset = NPA_Dataset(history_articles, impression_user_data_test, candidate_news_data_test, articles_embeddings_dict)\n",
    "\n",
    "\n",
    "#BAAAAAAAATCH\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, collate_fn=collate_fn, num_workers=8,  pin_memory=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, collate_fn=collate_fn)\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "model = NPA_Model(num_filters=32, filter_size=16)\n",
    "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = torch.nn.BCELoss()  # Binary Cross-Entropy Loss for binary classification\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "\n",
    "def ndcg_at_k(y_true, y_pred, k=3):\n",
    "    # Get top-k indices and gather corresponding labels from `y_true`\n",
    "    _, top_k_indices = torch.topk(y_pred, k, dim=-1)\n",
    "    top_k_labels = torch.gather(y_true, 1, top_k_indices).squeeze()\n",
    "\n",
    "    # Calculate DCG\n",
    "    gain = (2 ** top_k_labels - 1).float()\n",
    "    discounts = torch.log2(torch.arange(k, dtype=torch.float32, device=y_pred.device) + 2)\n",
    "    dcg = torch.sum(gain / discounts, dim=-1)\n",
    "\n",
    "    # Calculate ideal DCG\n",
    "    sorted_labels, _ = torch.sort(y_true, descending=True)\n",
    "    ideal_gain = (2 ** sorted_labels[:, :k] - 1).float()\n",
    "    idcg = torch.sum(ideal_gain / discounts, dim=-1)\n",
    "\n",
    "    # Calculate nDCG\n",
    "    ndcg = torch.where(idcg == 0, torch.zeros_like(dcg), dcg / idcg)\n",
    "    return ndcg.mean()\n",
    "\n",
    "#########################################\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler()  # Initialize GradScaler for mixed precision\n",
    "\n",
    "def train_mixed_precision(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    ndcg_score = 0\n",
    "    counter_batch = 1\n",
    "    for batch in dataloader:\n",
    "        print(f'Starting batch number {counter_batch}')\n",
    "        counter_batch += 1\n",
    "        (candidate_news, clicked_news, user_features, candidate_mask, clicked_mask), labels = batch\n",
    "        candidate_news = candidate_news.to(device)\n",
    "        clicked_news = clicked_news.to(device)\n",
    "        user_features = user_features.to(device)\n",
    "        candidate_mask = candidate_mask.to(device)\n",
    "        clicked_mask = clicked_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Mixed precision forward pass\n",
    "        with torch.cuda.amp.autocast():\n",
    "            outputs = model(candidate_news, clicked_news, user_features, candidate_mask, clicked_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        print(f\"Loss: {loss} total loss: {total_loss}\")\n",
    "\n",
    "        ndcg_score += ndcg_at_k(labels, outputs, k=3).item()\n",
    "        print(f\"Ncdg score: {ndcg_score}\")\n",
    "\n",
    "        # Mixed precision backward pass\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "    return total_loss / len(dataloader), ndcg_score / len(dataloader)\n",
    "\n",
    "\n",
    "\n",
    "#########################################\n",
    "\n",
    "\n",
    "# Training loop remains the same\n",
    "def train(model, dataloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    ndcg_score = 0\n",
    "    counter_batch = 1\n",
    "    for batch in dataloader:\n",
    "        print(f'Starting batch number {counter_batch}')\n",
    "        counter_batch += 1\n",
    "        (candidate_news, clicked_news, user_features, candidate_mask, clicked_mask), labels = batch\n",
    "        candidate_news = candidate_news.to(device)\n",
    "        clicked_news = clicked_news.to(device)\n",
    "        user_features = user_features.to(device)\n",
    "        candidate_mask = candidate_mask.to(device)\n",
    "        clicked_mask = clicked_mask.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(candidate_news, clicked_news, user_features, candidate_mask, clicked_mask)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        total_loss += loss.item()\n",
    "        print(f\"Loss: {loss} total loss: {total_loss}\")\n",
    "\n",
    "        # Compute nDCG@k metric\n",
    "        ndcg_score += ndcg_at_k(labels, outputs, k=3).item()\n",
    "        print(f\"Ncdg score: {ndcg_score}\")\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return total_loss / len(dataloader),  ndcg_score / len(dataloader)\n",
    "\n",
    "\n",
    "\n",
    "def test(model, dataloader, criterion, device, k=3):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    total_loss = 0\n",
    "    ndcg_score = 0\n",
    "\n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for batch in dataloader:\n",
    "            (candidate_news, clicked_news, user_features, candidate_mask, clicked_mask), labels = batch\n",
    "            candidate_news = candidate_news.to(device)\n",
    "            clicked_news = clicked_news.to(device)\n",
    "            user_features = user_features.to(device)\n",
    "            candidate_mask = candidate_mask.to(device)\n",
    "            clicked_mask = clicked_mask.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(candidate_news, clicked_news, user_features, candidate_mask, clicked_mask)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Compute nDCG@k metric\n",
    "            ndcg_score += ndcg_at_k(labels, outputs, k=3).item()\n",
    "\n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    avg_ndcg = ndcg_score / len(dataloader)\n",
    "\n",
    "    return avg_loss, avg_ndcg\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "b4TxnSl0nmeZ",
    "outputId": "9a0446de-2fb6-4bbc-e7f3-bbd2be82f09d"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import os\n",
    "import time\n",
    "# Set device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "\n",
    "# Number of epochs and early stopping patience\n",
    "epochs = 10\n",
    "patience = 3  # Number of epochs to wait for improvement before stopping\n",
    "best_val_loss = float('inf')  # Initialize to a very high value\n",
    "patience_counter = 0  # Counts epochs without improvement\n",
    "# Format the time as needed, e.g., year-month-day_hour-minute\n",
    "current_time = time.strftime(\"%Y%m%d_%H%M\", time.localtime())\n",
    "checkpoint_path = f\"model_checkpoint_64batch_{current_time}.pth\"  # Checkpoint file path\n",
    "\n",
    "##TRyING MIXED PRECISION TO ccelea=rate trainiing\n",
    "try:\n",
    "    for epoch in range(epochs):\n",
    "        # Training phase\n",
    "        train_loss, train_ndcg = train(model, train_loader, criterion, optimizer, device)\n",
    "\n",
    "        # Validation phase\n",
    "        val_loss, val_ndcg = test(model, val_loader, criterion, device, k=5)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val nDCG@5: {val_ndcg:.4f}\")\n",
    "\n",
    "        # Check for improvement\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0  # Reset patience counter\n",
    "            # Save the best model as a checkpoint\n",
    "            torch.save(model.state_dict(), checkpoint_path)\n",
    "            print(f\"Model improved, saving new checkpoint to {checkpoint_path}\")\n",
    "        else:\n",
    "            patience_counter += 1  # Increment patience counter if no improvement\n",
    "\n",
    "        # Early stopping if validation loss hasn't improved for 'patience' epochs\n",
    "        if patience_counter >= patience:\n",
    "            print(\"Early stopping triggered. No improvement in validation loss.\")\n",
    "            break\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"Training interrupted by user. Saving model checkpoint...\")\n",
    "    torch.save(model.state_dict(), \"interrupted_checkpoint.pth\")\n",
    "    print(\"Checkpoint saved at interrupted_checkpoint.pth\")\n",
    "\n",
    "# Ensure model is saved at the end\n",
    "final_path = f\"final_model_64batch_{current_time}.pth\"\n",
    "torch.save(model.state_dict(), final_path)\n",
    "print(f\"Training complete. Final model saved at {final_path}\")\n",
    "\n",
    "# Load the best model and evaluate on the test set\n",
    "model.load_state_dict(torch.load(checkpoint_path))  # Load the best model based on validation\n",
    "test_loss, test_ndcg = test(model, test_loader, criterion, device, k=5)\n",
    "print(f\"Test Loss: {test_loss:.4f}, Test nDCG@5: {test_ndcg:.4f}\")\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9yfBsystO0Dc",
    "outputId": "e4139030-7ca2-4323-9be1-01a181c25030"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
